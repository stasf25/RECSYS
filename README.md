# Инсталляция рекомендательной системы

## Склонируйте репозиторий

Склонируйте репозиторий проекта:

```
https://github.com/stasf25/mle-pr-final.git
```

## Активируйте виртуальное окружение

Перейдите в корневую директорию проекта и
создайте виртуальное окружение командой:

```
source inst_venv
```

## Задайте параметры конфигурации системы

Параметры конфигурации системы расположены в двух файлах в корневой
директоии проекта:

- файл `.env` содержит ***параметры подключения*** к хранилищу S3 и базе
данных postgres, необходимой для функционирования сервера MLFlow.
> **<ins>Важно:</ins>**  
> Данный файл не включен в состав репозитория, но может быть
сформирован, например, на основании шаблона `env.template`, расположенного
в корневой директории проекта и содержащего несекретную часть параметров подключения.

- файл `env.services` содержит прочие параметры, необходимые для работы системы.

## Постройте необходимые docker-контейнеры

Для построения контейнеров выполните из корневой директории проекта команду
```
./build_all
```


# Общее описание проекта

Проект состоит из трех компонентов, которые необходимо 
запускать в отдельных терминальных окнах **из корневой директории проекта**:

- основной сервис рекомендательной системы;
- AirFlow-сервер, с помощью которого запускается DAG, реализующий логику 
формирования данных для оффлайн-рекомендаций;
- MLFlow-сервер, с помощью которого сохраняются регулярно обновляемые версии
модели ранжирования.

## Основной сервис рекомендательной системы

Основной сервис рекомендательной системы реализован в виде пяти docker-контейнеров,
конфигурационные файлы которых расположены в директории `services/`, а исходные
тексты - в директории `services/ml_service/`:

- `recsys_app` - собственно микросервис выдачи рекомендаций (исходные коды: `recommendations_service.py` и `rec_store.py`);
- `events_store` - микросервис получения информации о текущих взаимодействиях
пользователей со внешними по отношению к рекомендательной системе бизнес-объектами (исходный код: `events_store.py`);
- `features_store` - микросервис формирования онлайн-рекомендаций на основе
информации о текущих взаимодействиях пользователей с бизнес-объектами (исходный код: `features_store.py`);
- `prom/prometheus` - сервис сбора данных для мониторинга работы recsys_app;
- `grafana/grafana` - сервис мониторинга работы recsys_app.


## DAG формирования данных для оффлайн-рекомендаций

Конфигурационные файлы для сборки контейнеров системы AirFlow, в рамках которой 
функционирует DAG, расположены в директории `airflow/`, а исходные коды DAG-а - в 
директории `airflow/dags/`.

В указанной директории расположены 2 файла: `prepare_recs.py`, обеспечивающий
конфигурирование и общую логику работы DAG-а, и файл `data_handlers.py`, содержащий
программные коды для загрузки и очиски данных, обучения моделей формирования и
ранжирования рекомендаций с подбором гиперпараметров,
формирования файлов данных для микросервисов рекомендательной системы, а также
подачи указанным микросервисам сигнала о необходимости загрузки новых данных.

> **<ins>Важно:</ins>**  
> Для взаимодействия с микросервисами рекомендательной системы, а также с
сервером MLFlow, DAG-у необходим IP-адрес хоста, на котором развернута система.
В случае, если хост имеет внешний IP-адрес, дополнительные настройки не требуются
(указанный адрес будет получен автоматически). В противном случае необходимо
в файле `env.services` раскомментировать и соответствующим образом заполнить 
строку, содержащую параметр `HOST_IP`.

Программный код в файле `prepare_recs.py` поддерживает работу в одном из двух
режимов функционирования рекомендательной системы: `ручном`, предполагающем 
оценку ML-инженером качества модели ранжирования и принятие ***им*** решения о 
вводе модели в промышленную эксплуатацию, и `автономном`, при котором обученная 
на новых
данных модель ранжирования сразу применяется для формирования файлов рекомендаций,
непосредственно используемых рекомендательной системой.

Выбранный режим функционирования оказывает непосредственное влияние на логику
выполнения шагов DAG-а. 

В `ручном` режиме подбор гиперпараметров моделей (который
может занять продолжительное время) осуществляется после формирования файлов
офлайн-рекомендаций и после подачи микросервисам рекомендательной системы сигнала
о необходимости загрузки новых данных. При этом файлы, содержащие новые гиперпараметры
и обученную модель ранжирования, ***не*** замещают версию указанных файлов, использовавшуюся
при формировании рекомендаций.

В `автономном` режиме подбор гиперпараметров моделей на новых данных осуществляется
до расчета и формирования файлов офлайн-рекомендаций. Файлы, содержащие новые гиперпараметры
и обученную модель ранжирования, ***замещают*** версию указанных файлов, используюмую
для формирования рекомендаций.

Переключение режимов функционирования системы осуществляется соответствующей (ON/OFF) 
установкой параметра `AUTONOMOUS_MODE` в файле `env.services`.

По умолчанию, автономный режим отключен.

Все операции осуществяются DAG-ом с данными, размещенными в хранилище S3.
Связь с хранилищем устанавливается автоматически на основании параметров, содержащихся
в файле `.env`. Настройка соединения через AirFlow UI **не требуется**.

## Сервер MLFLOW

Сервер MLFlow настроен на использование БД postgress в качестве
backend и хранилища S3 для сохранения моделей и артефактов. Параметры запуска сервера
содержатся в файле `services/mlflow/run_mlflow_server_remote`

Сервер может быть, также, запущен в локальном режиме. Параметры для запуска сервера
в локальном режиме содержатся в файле `services/mlflow/run_mlflow_server_local`

## Структура файлового хранилища

Виртуальная директория `S3://s3-student-mle-20250228-1d75c84a52/Diplom` состоит
из следующих "поддиректорий":

- `source_data/`: содержит исходные данные проекта в виде набора csv-файлов;
- `infer_data/` : содержит обработанные и очищенные данные, получаемые в результате
выполнения шага `prepare_data` DAG-а;
- `recommendations/`: файлы, содержащие расчитанные оффлайн-рекомендации, получаемые
в результате выполнения шага `calc_recommendations` DAG-а и непосредственно используемые
микросервисами рекомендательной системы;
- `model/`: файлы, содержащие сохраненную модель ранжирования, а также гиперпараметры,
использованные при формировании содержимого `recommendations/`;
- `model_retrained/`: файлы, содержащие сохраненную модель ранжирования и гиперпараметры,
полученные в `ручном` режиме функционирования системы в результате выполнения
шага `retrain_models` DAG-а;
- `mlruns/`: хранилище артефактов MLFlow;
- `data/`: рабочие данные, полученные в результате исследований и 
экспериментов в ходе работы над проектом.

# Запуск системы

Для запуска системы используются следующие скрипты из корневой
директории проекта:

- запуск рекомендательной системы:
```
./run_serv
```

- запуск сервера MLFlow:
```
./mlf

либо:
./mlfloc
```

- запуск AirFlow:
```
./airup
```

После инициализации всех компонентов, на хосте открываются следующие порты:

- http://localhost:8080 - UI сервера AirFlow;
- http://localhost:8090 - основной микросервис рекомендательной системы (`recsys_app`);
- http://localhost:8091 - микросервис `features_store`;
- http://localhost:8092 - микросервис `events_store`;
- http://localhost:9090 - UI сервера Prometheus;
- http://localhost:3000 - UI сервера Grafana;
- http://localhost:5000 - UI сервера MLFlow

На портах микросервисов рекомендательной системы доступен UI swagger для тестирования REST API.


## Нагрузочное тестирование

Для проведения нагрузочного тестирования запустите скрипт симуляции нагрузки:
```
./workload
```

Скрипт генерирует заданное количество запросов в течение заданного количества секунд.
Сэмплы для генерации нагрузки берутся из S3-файла `infer_data/last_events.parquet`,
формируемого AirFlow DAG-ом на шаге `prepare_data` из данных исходного файла `events.csv`,
выходящих за пределы периода, принимаемого в расчет при формировании рекомендаций
(период, ограниченный сверху датой самых свежих данных в файле `item_properties.csv`).

Динамику изменения нагрузок можно в онлайне наблюдать в системе мониторинга (Grafana).

Параметры настройки устанавливаются вручную в теле скрипта (`services/scripts/workload.py`):
```
# Параметры  тестирования  --------------------------------------------------------------
OVERALL_TEST_TIME_SEC = 900     # время, в которое, по-возможности, должен уложиться тест
MAX_TEST_SAMPLES = 20000        # -1 - без ограничений (~41тыс. запросов)
DELAYED_REQUESTS_RATE = 0.005   # доля запросов с 10-и кратной задержкой
# ---------------------------------------------------------------------------------------
```

## Остановка системы

Для остановки всех docker-контейнеров выполните скрипт
```
./down_all
```
Сервер MLFlow останавливается путем нажатия Ctrl-C в его терминальном окне.



# Мониторинг работы системы

Дашборд для мониторинга работы системы включает 6 панелей,
размещенных на 1-ом экране (без необходимости скроллинга).
Внешний вид дашборда и его json-описание приведены в файлах
`services/monitoring/dashboard.png` и `services/monitoring/dashboard.json`.


## Для мониторинга работы системы выбраны метрики нескольких слоев:

### Метрики Инфраструткурного слоя:
- динамика количества http-запросов к микросервису;
- среднее время обработки запроса.

Эти метрики характеризуют сетевой траффик и способность
микросервися справляться с ним.  
Используется линейный график, потому что он наиболее простым
и наглядным образом отражает изменение указанных метрик с
течением времени.


### Метрики реального времени:
- нагрузка на CPU
- использование оперативной памяти

Эти метрики характеризуют нагрузку на ключевые аппаратные ресурсы.
Отображение данных метрик разнесено на 2 панели: на одной отображается
их текущее состояние на момент скраппирования, а на второй - изменение
значений метрик с течением времени с отражением фактов достижения
пороговых значений.


### Метрики прикладного уровня:
- медиана и квантили 5% и 95% доли оффлайн-рекомендаций в общем количестве сформированных рекомендаций;
- круговая диаграмма с распределением долей по виду источника рекомендаций;
- динамика программных сбоев (exception) при обработке запросов в разбивке по микросервисам.

Существенное изменение медианного значения и/или квантилей распределения
является свидетельством глобального изменения характеристик
объектов, в отношении которых запрашиваются предсказания и/или бизнес-среды, что может быть 
сигналом к целесообразности проведения дополнительных исследований на актуальных данных.

Наличие фактов сбоев при обработке запросов является сигналом к немедленному вмешательству
с целью устранения причин таких сбоев.


# Дополнительные возможности

Сервис рекомендаций может быть запущен в тестовом режиме, при котором подробный журнал
работы его микроcервисов отписывается в файл `logs/test_service.log`

Запуск сервиса рекомендаций в тестовом режиме:
```
./run_test
```
Текст скрипта, содержащего тестовые запросы, находится в 
файле `services/scripts/test_service.py`.

Запуск скрипта:
```
./test_service
```

Содержимое журнала должно помочь убедиться в том,
что для пользователей, имеющих как персонифицированные оффлайн-рекомендации, так и онлайн-взаимодействия,
сервис выдает смешанный список рекомендаций, в котором на нечетных местах стоят онлайн-, а на
четных - оффлайн-рекомендации (нумерация мест начинается с 1 :)

