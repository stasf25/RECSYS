{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s',force=True)\n",
    "#logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',force=True)# stream=sys.stdout)\n",
    "logging.info(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib,subprocess,requests,io\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from   s3fs   import S3FileSystem\n",
    "# -------------------------------------------------\n",
    "#    системные функции\n",
    "# -------------------------------------------------\n",
    "\n",
    "def host_ip():\n",
    "    ''' Возвращает ip-адрес текущего хоста '''\n",
    "    return subprocess.run(['curl', 'ifconfig.co/'], capture_output=True, text=True).stdout.strip()\n",
    "\n",
    "def post_request(url, params=None):\n",
    "    ''' Формирует POST-запрос к заданному сервису '''\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "\n",
    "    resp = requests.post(url, headers=headers, params=params)\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        recs = resp.json()\n",
    "    else:\n",
    "        recs = {\"result\": \"ERROR\", \"code\": f\"{resp.status_code}\"}\n",
    "        logging.error(f\"Error status code: {resp.status_code} received from {url} ({params})\")\n",
    "    return recs\n",
    "\n",
    "def pd_info(df: pd.DataFrame):\n",
    "    ''' Отписывает результат pd.DataFrame.info в строку (для logging) '''\n",
    "    with io.StringIO() as output:\n",
    "        df.info(show_counts=True, buf=output)\n",
    "        return output.getvalue()\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "#    функции работы с файлами в хранилище S3\n",
    "# -------------------------------------------------\n",
    "\n",
    "def load_csv_files(s3: S3FileSystem, path_list: list):\n",
    "    try:\n",
    "        df = pd.DataFrame()\n",
    "        for path in path_list:\n",
    "            with s3.open(path, mode='r') as fd:\n",
    "                df = pd.concat([df, pd.read_csv(fd)], axis=0, ignore_index=True)\n",
    "        return df\n",
    "    except:\n",
    "        logging.warning(f\"Error loading file: {path}\")\n",
    "        return None\n",
    "\n",
    "def load_parquet_file(s3: S3FileSystem, path: str):\n",
    "    try:\n",
    "        df = pd.DataFrame()\n",
    "        with s3.open(path, mode='rb') as fd:\n",
    "            df = pd.read_parquet(fd)\n",
    "        return df\n",
    "    except:\n",
    "        logging.error(f\"Error loading file: {path}\")\n",
    "        return None\n",
    "\n",
    "def load_pkl_file(s3: S3FileSystem, path: str):\n",
    "    try:\n",
    "        with s3.open(path, mode='rb') as fd:\n",
    "            obj = joblib.load(fd)\n",
    "        return obj\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error {e} loading file: {path}\")\n",
    "        return None\n",
    "\n",
    "def save_to_parquet(df, s3: S3FileSystem, path: str, verbose=True):\n",
    "    with s3.open(path, mode='wb') as fd:\n",
    "        df.to_parquet(fd)\n",
    "    if verbose:  logging.info(f\"save_to_parquet:\\n{path}\\n{pd_info(df)}\")\n",
    "    return\n",
    "\n",
    "def save_to_pkl(obj, s3: S3FileSystem, path: str, verbose=True):\n",
    "    with s3.open(path, mode='wb') as fd:\n",
    "        joblib.dump (obj, fd)\n",
    "    if verbose:  logging.info(f\"save_to_pkl: {path}\")\n",
    "    return\n",
    "\n",
    "def delete_s3_files(s3: S3FileSystem, files: dict):\n",
    "    for k,path in files.items():\n",
    "        s3.rm(path)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "#    функции для извлечения item properties\n",
    "# -------------------------------------------------\n",
    "\n",
    "def get_registered_items(timestamp, items_ctgr):\n",
    "    ''' Возвращает набор itemid, для которых определена корректная категория на заданный момент времени '''\n",
    "    return  set(items_ctgr.query(\"timestamp <= @timestamp\")['itemid'])\n",
    "\n",
    "def get_unavailable_items(timestamp, items_avail):\n",
    "    ''' Возвращает набор itemid, для которых установлен признак available==0 на заданный момент времени '''\n",
    "    tmp = items_avail.query(\"timestamp <= @timestamp\").drop_duplicates(subset=['itemid'], keep='first')\n",
    "    return  set(tmp.query(\"value == '0'\")['itemid'])\n",
    "\n",
    "def get_available_items(timestamp, items_ctgr, items_avail):\n",
    "    ''' Возвращает набор itemid, доступных на заданный момент времени '''\n",
    "    return  get_registered_items(timestamp, items_ctgr) - get_unavailable_items(timestamp, items_avail)\n",
    "\n",
    "def get_item_availability(timestamp, items_ctgr, items_avail):\n",
    "    ''' Возвращает признак доступности товаров, актуальный на заданный момент времени '''\n",
    "    lst = get_registered_items(timestamp, items_ctgr)\n",
    "    tmp = items_avail.query(\"timestamp <= @timestamp and itemid in @lst\") \\\n",
    "                     .drop_duplicates(subset=['itemid'], keep='first').reset_index(drop=True)\n",
    "    return  tmp[['itemid','value']]\n",
    "\n",
    "def get_item_category(timestamp, items_ctgr):\n",
    "    ''' Возвращает категории товаров, актуальные на заданный момент времени '''\n",
    "    tmp = items_ctgr.query(\"timestamp <= @timestamp\") \\\n",
    "                    .drop_duplicates(subset=['itemid'], keep='first').reset_index(drop=True)\n",
    "    return  tmp[['itemid','categoryid']]\n",
    "\n",
    "def get_item_properties(timestamp, items):\n",
    "    ''' Возвращает свойства товаров/товара, актуальные на заданный момент времени '''\n",
    "    tmp = items.query(\"timestamp <= @timestamp\") \\\n",
    "               .drop_duplicates(subset=['itemid','property'], keep='first').reset_index(drop=True)\n",
    "    return  tmp[['itemid','property','value_code']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'89.169.168.158'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#from   airflow.models.connection          import Connection\n",
    "#from   airflow.utils.session              import create_session\n",
    "#from   airflow.providers.amazon.aws.fs.s3 import get_fs\n",
    "from   dotenv     import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv(\"env.services\"))\n",
    "\n",
    "S3_DIR          = f\"{os.environ['S3_BUCKET_NAME']}/Diplom\"\n",
    "AWS_ACCESS_KEY  = os.environ['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_KEY  = os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "S3_ENDPOINT_URL = os.environ['AWS_ENDPOINT_URL']\n",
    "MY_HOST         = host_ip()  if not \"HOST_IP\" in os.environ  else os.environ['HOST_IP']\n",
    "\n",
    "# параметры конфигурации DAG-а\n",
    "CONFIG      = {\n",
    "    \"EVENT_HISTORY_WEEKS\": 26,  # сохранять events только за последние подгода\n",
    "    \"EVENT_POPULAR_WEEKS\": 12,  # глубина истории (в неделях) для определения популярных товаров\n",
    "    \"EVENT_TARGET_WEEKS\" : 2,   # количество недель для target-периода (в режиме переобучения моделей)\n",
    "    \"EVENT_TEST_WEEKS\"   : 1,   # количество недель для test-периода (в режиме переобучения моделей)\n",
    "    \"EVENT_CUT_OFF_WEEKS\": 4,   # количество недель для inference-периода (в режиме расчета рекомендаций)\n",
    "    \"ALS_RECS_PER_USER\"  : 15,  # количество коллаборативных рекомендаций на пользователя\n",
    "    \"ALS_SIMS_PER_ITEM\"  : 15,  # количество подобных товаров на основе коллаборативных рекомендаций\n",
    "    \"EXPERIMENT_NAME\"    : f\"{os.environ['MLFLOW_EXPERIMENT_NAME']}\",\n",
    "    \"MODEL_NAME\"         : f\"{os.environ['MLFLOW_MODEL_NAME']}\",\n",
    "    \"MLFLOW_SERVER_URL\"  : f\"http://{MY_HOST}:{os.environ['MLFLOW_SERVER_PORT']}\",\n",
    "}\n",
    "\n",
    "# используемые ресурсы\n",
    "SRC_FILES = {\n",
    "    \"cats_src\" : f\"{S3_DIR}/source_data/category_tree.csv\",\n",
    "    \"props_src\":[f\"{S3_DIR}/source_data/item_properties_part1.csv\",\n",
    "                    f\"{S3_DIR}/source_data/item_properties_part2.csv\"],\n",
    "    \"event_src\": f\"{S3_DIR}/source_data/events.csv\"\n",
    "}\n",
    "INFER_FILES = {\n",
    "    \"cats_dst\" : f\"{S3_DIR}/infer_data/category_tree.parquet\",\n",
    "    \"item_cat\" : f\"{S3_DIR}/infer_data/item_categories.parquet\",\n",
    "    \"item_prop\": f\"{S3_DIR}/infer_data/item_properties.parquet\",\n",
    "    \"available\": f\"{S3_DIR}/infer_data/item_availability.parquet\",\n",
    "    \"event_dst\": f\"{S3_DIR}/infer_data/events.parquet\",\n",
    "    \"eventlast\": f\"{S3_DIR}/infer_data/last_events.parquet\",\n",
    "}\n",
    "PROD_FILES = {\n",
    "    \"top_pop\"  : f\"{S3_DIR}/recommendations/top_popular.parquet\",\n",
    "    \"similar\"  : f\"{S3_DIR}/recommendations/similar_items.parquet\",\n",
    "    \"ranked\"   : f\"{S3_DIR}/recommendations/ranked_candidades.parquet\",\n",
    "    \"final\"    : f\"{S3_DIR}/recommendations/final_recommendations.parquet\"\n",
    "}\n",
    "MODEL_FILES = {\n",
    "    \"als_parms\": f\"{S3_DIR}/model/als_params.pkl\",\n",
    "    \"cb_parms\" : f\"{S3_DIR}/model/cb_params.pkl\",\n",
    "    \"cb_model\" : f\"{S3_DIR}/model/cb_model.pkl\"\n",
    "}\n",
    "REC_SERVICES= {\n",
    "    \"rec_serv\" : f\"http://{MY_HOST}:{os.environ['RECOMMENDATIONS_PORT']}\",\n",
    "    \"features\" : f\"http://{MY_HOST}:{os.environ['FEATURES_STORE_PORT']}\",\n",
    "    \"events\"   : f\"http://{MY_HOST}:{os.environ['EVENTS_STORE_PORT']}\",\n",
    "}\n",
    "\n",
    "MY_HOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3FileSystem(\n",
    "    endpoint_url=os.environ['AWS_ENDPOINT_URL'],\n",
    "    key=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "    secret=os.environ['AWS_SECRET_ACCESS_KEY'], cache_regions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from   sklearn.preprocessing   import MinMaxScaler\n",
    "from   implicit.als            import AlternatingLeastSquares\n",
    "from   implicit.evaluation     import mean_average_precision_at_k, ndcg_at_k, AUC_at_k\n",
    "from   sklearn.model_selection import ParameterGrid\n",
    "from   catboost                import CatBoostClassifier, Pool\n",
    "from   catboost.utils          import eval_metric\n",
    "from   threadpoolctl           import threadpool_limits\n",
    "threadpool_limits(1, \"blas\")\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def calc_item_rating(df):\n",
    "    ''' Формирует вектор рейтинга взаимодействий: наличие просмотров + добавления в корзину + покупки*2 '''\n",
    "    return ((df[0] > 0) + df[1] + df[2]*2).astype(np.int16)\n",
    "\n",
    "def user_item_matrix(events_set, users, items):\n",
    "    ''' Формирует и возвращает матрицу взаимодействий в dense и sparse формате '''\n",
    "    user_item = events_set.query(\"visitorid in @users  and  itemid in @items\")     \\\n",
    "                            .groupby(['visitorid','itemid'])['event'].value_counts() \\\n",
    "                            .unstack(fill_value=0).reset_index()\n",
    "    # формируем рейтинг взаимодействий\n",
    "    user_item['rating'] = 0  if user_item.shape[0]==0  else calc_item_rating(user_item)\n",
    "    return user_item, scipy.sparse.csr_matrix(\n",
    "        (user_item['rating'], (user_item['visitorid'], user_item['itemid'])), \n",
    "            shape=(users.max()+1, items.max()+1)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_validate(csr_train, csr_val, k=10, **kwargs):\n",
    "    ''' Обучает и валидирует ALS с заданными гиперпараметрами '''\n",
    "    model = AlternatingLeastSquares(random_state=RANDOM_STATE, **kwargs)\n",
    "    model.fit(csr_train, show_progress=False)\n",
    "    map_k = 0 if csr_val is None  \\\n",
    "            else mean_average_precision_at_k(model, csr_train, csr_val, k, show_progress=False)\n",
    "    return  model, map_k\n",
    "\n",
    "def als_train(csr_train, csr_val, **hyper_params):\n",
    "    ''' Обучает ALS с возможным подбором гиперпараметров '''\n",
    "\n",
    "    if hyper_params:\n",
    "        model,_ = als_validate(csr_train, None, **hyper_params)\n",
    "        return  model, hyper_params\n",
    "    \n",
    "    # подбор гиперпараметров\n",
    "    grid = {\n",
    "        'alpha':[30.0,50.0,70.0,100.0], 'regularization':[0.005,0.01,0.05], \n",
    "        'iterations':[10,15,20,25],     'factors':[50,100,150,200]\n",
    "    }\n",
    "    test_grid   = {'alpha':[100.0], 'factors':[100], 'iterations':[15], 'regularization':[0.005]}\n",
    "    best_metric = 0\n",
    "    best_params = {}\n",
    "    best_model  = None\n",
    "\n",
    "    for params in list(ParameterGrid(test_grid)):     # в prom-e ЗАМЕНИТЬ test_grid НА grid !!!\n",
    "        model, metric = als_validate(csr_train, csr_val, **params)\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_params = params\n",
    "            best_model  = model\n",
    "    return  best_model, best_params\n",
    "\n",
    "\n",
    "\n",
    "def als_train_bayes(csr_train, csr_val, **hyper_params):\n",
    "    ''' Обучает ALS с возможным подбором гиперпараметров '''\n",
    "\n",
    "    if hyper_params:\n",
    "        model,_ = als_validate(csr_train, None, **hyper_params)\n",
    "        return  model, hyper_params\n",
    "    \n",
    "    from skopt           import BayesSearchCV\n",
    "    from sklearn.base    import BaseEstimator\n",
    "    best_model= None\n",
    "    best_score= 0\n",
    "    als_cache = dict()\n",
    "\n",
    "    class ScikitAls (BaseEstimator):\n",
    "        def __init__(self, factors=100, regularization=0.01, alpha=1.0, iterations=3, **kwargs):\n",
    "            self.factors=factors\n",
    "            self.regularization=regularization\n",
    "            self.alpha=alpha\n",
    "            self.iterations=iterations\n",
    "            self.params=kwargs\n",
    "        def fit(self, X, y=None):\n",
    "            nonlocal best_model, best_score, als_cache\n",
    "            if  f\"{self.get_params()}\" in als_cache.keys(): return\n",
    "            self.als = AlternatingLeastSquares(random_state=RANDOM_STATE, **self.get_params())\n",
    "            self.als.fit(csr_train, **self.params)\n",
    "        def predict(self, X):\n",
    "            return X\n",
    "        def calc_score(self):\n",
    "            nonlocal best_model, best_score, als_cache\n",
    "            key = f\"{self.get_params()}\"\n",
    "            if  key not in als_cache.keys():\n",
    "                #als_cache[key]= round(mean_average_precision_at_k(self.als, csr_train, csr_val, 10, show_progress=False), 5)\n",
    "                als_cache[key]= round(ndcg_at_k(self.als, csr_train, csr_val, 10, show_progress=False), 5)\n",
    "                if  best_score < als_cache[key]:\n",
    "                    best_score = als_cache[key]\n",
    "                    best_model = self.als\n",
    "                print (f\"score [{key}] => {als_cache[key]}\")\n",
    "            return als_cache[key]\n",
    "\n",
    "\n",
    "    def als_scorer(estimator, X, y=None):\n",
    "        return  estimator.calc_score()\n",
    "\n",
    "    \n",
    "    searchcv = BayesSearchCV(\n",
    "        ScikitAls(random_state=RANDOM_STATE),\n",
    "        search_spaces={\n",
    "            'regularization': (0.005, 1.0, 'log-uniform'),\n",
    "            'alpha':          (1.0, 100.0, 'uniform'),\n",
    "            'iterations':     (10,    25),\n",
    "            'factors':        (30,   150)\n",
    "        },\n",
    "        fit_params={'show_progress': True},\n",
    "        scoring=als_scorer,\n",
    "        n_iter=30,\n",
    "        cv=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    searchcv.fit(csr_train)\n",
    "    return  best_model, dict(searchcv.best_params_)\n",
    "\n",
    "\n",
    "from implicit.cpu.bpr import BayesianPersonalizedRanking\n",
    "def als_train_(csr_train, csr_val, **hyper_params):\n",
    "    ''' Обучает ALS с возможным подбором гиперпараметров '''\n",
    "\n",
    "    if hyper_params:\n",
    "        model,_ = als_validate(csr_train, None, **hyper_params)\n",
    "        return  model, hyper_params\n",
    "    \n",
    "    from skopt           import BayesSearchCV\n",
    "    from sklearn.base    import BaseEstimator\n",
    "    best_model= None\n",
    "    best_score= 0\n",
    "    als_cache = dict()\n",
    "\n",
    "    class ScikitAls (BaseEstimator):\n",
    "        def __init__(self, factors=100, regularization=0.01, learning_rate=0.01, iterations=100, **kwargs):\n",
    "            self.factors=factors\n",
    "            self.regularization=regularization\n",
    "            self.learning_rate=learning_rate\n",
    "            self.iterations=iterations\n",
    "            self.params=kwargs\n",
    "        def fit(self, X, y=None):\n",
    "            nonlocal best_model, best_score, als_cache\n",
    "            if  f\"{self.get_params()}\" in als_cache.keys(): return\n",
    "            self.als = BayesianPersonalizedRanking(random_state=RANDOM_STATE, **self.get_params())\n",
    "            self.als.fit(csr_train, **self.params)\n",
    "        def predict(self, X):\n",
    "            return X\n",
    "        def calc_score(self):\n",
    "            nonlocal best_model, best_score, als_cache\n",
    "            key = f\"{self.get_params()}\"\n",
    "            if  key not in als_cache.keys():\n",
    "                #als_cache[key]= round(mean_average_precision_at_k(self.als, csr_train, csr_val, 10, show_progress=False), 5)\n",
    "                als_cache[key]= round(AUC_at_k(self.als, csr_train, csr_val, 10, show_progress=False), 5)\n",
    "                if  best_score < als_cache[key]:\n",
    "                    best_score = als_cache[key]\n",
    "                    best_model = self.als\n",
    "                print (f\"score [{key}] => {als_cache[key]}\")\n",
    "            return als_cache[key]\n",
    "\n",
    "\n",
    "    def als_scorer(estimator, X, y=None):\n",
    "        return  estimator.calc_score()\n",
    "\n",
    "    \n",
    "    searchcv = BayesSearchCV(\n",
    "        ScikitAls(random_state=RANDOM_STATE),\n",
    "        search_spaces={\n",
    "            'regularization': (0.005, 1.0, 'log-uniform'),\n",
    "            'learning_rate':  (0.005, 1.0, 'log-uniform'),\n",
    "            'iterations':     (10,   100),\n",
    "            'factors':        (30,   150)\n",
    "        },\n",
    "        fit_params={'show_progress': True},\n",
    "        scoring=als_scorer,\n",
    "        n_iter=50,\n",
    "        cv=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    searchcv.fit(csr_train)\n",
    "    print (f\"=== BEST SCORE: {best_score} ===\")\n",
    "    return  best_model, dict(searchcv.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_model(model, X, y_pred, metrics, params, config, artifacts=None, runid=None, desc=\"Test mlflow environment\"):\n",
    "    import mlflow \n",
    "    MODEL_NAME = config[\"MODEL_NAME\"]\n",
    "\n",
    "    mlflow.set_tracking_uri(config['MLFLOW_SERVER_URL'])\n",
    "    logging.info(f\"MLFlow tracking URL set to: {mlflow.get_tracking_uri()}\")\n",
    "    experiment_id = mlflow.set_experiment(config['EXPERIMENT_NAME']).experiment_id\n",
    "    logging.info(f\"MLFlow experiment name/id: {config['EXPERIMENT_NAME']}/{experiment_id}\")\n",
    "\n",
    "    with mlflow.start_run(run_id=runid, run_name=f\"{MODEL_NAME}_run\", experiment_id=experiment_id, description=desc) as run:\n",
    "        run_id = run.info.run_id\n",
    "        if  model is not None:\n",
    "            input_example = X[:10]\n",
    "            signature     = mlflow.models.infer_signature(X, y_pred)\n",
    "            model_info    = mlflow.catboost.log_model(\n",
    "                cb_model             = model,\n",
    "                registered_model_name= MODEL_NAME,\n",
    "                input_example        = input_example,\n",
    "                signature            = signature,\n",
    "                await_registration_for=0,\n",
    "                artifact_path        = f'model'\n",
    "            )\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.set_tag('estimator', 'CatBoostClassifier')\n",
    "            logging.info(f\"Model <{MODEL_NAME}> registered successfully (run_id:{run_id})\")\n",
    "\n",
    "        if artifacts is not None:\n",
    "            for key,val in artifacts.items():\n",
    "                mlflow.log_dict(val, f\"{key}.json\")\n",
    "                logging.info(f\"MLFlow artifact {key}.json logged (run_id:{run_id})\")\n",
    "\n",
    "    logging.info(f\"MLFlow run {run_id} closed\")\n",
    "    return run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_train(train_pool):\n",
    "    ''' Обучает Catboost с подбором гиперпараметров '''\n",
    "\n",
    "    model = CatBoostClassifier(random_state=RANDOM_STATE, verbose=False, \n",
    "        auto_class_weights='Balanced', loss_function='Logloss', eval_metric='Recall'\n",
    "    )\n",
    "\n",
    "    grid = {\n",
    "        'learning_rate':[0.18, 0.16, 0.14, 0.12, 0.09, 0.03],\n",
    "        'l2_leaf_reg':  [1, 3, 5],\n",
    "        'depth'        :[4, 6, 8, 10],\n",
    "        'iterations'   :[10,100,500,1000],\n",
    "    }\n",
    "    test_grid = {\n",
    "        'l2_leaf_reg':  [   1,    3],\n",
    "        'learning_rate':[0.14, 0.12],\n",
    "        'iterations'   :[  10,  100],\n",
    "        'depth'        :[   6,    4],\n",
    "    }\n",
    "\n",
    "    result = model.grid_search(test_grid, X=train_pool, stratified=True, refit=True, \n",
    "        partition_random_seed=RANDOM_STATE, plot=False, verbose=False \n",
    "    )\n",
    "    logging.info(f\"cb_result: {result}\")\n",
    "    return  model, result['params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_train_new(X, y):\n",
    "    ''' Обучает Catboost с подбором гиперпараметров '''\n",
    "\n",
    "    model = CatBoostClassifier(random_state=RANDOM_STATE, verbose=False, \n",
    "        auto_class_weights='Balanced', loss_function='Logloss', #eval_metric='Recall'\n",
    "    )\n",
    "\n",
    "    from skopt import BayesSearchCV\n",
    "    searchcv = BayesSearchCV(\n",
    "        model,\n",
    "        search_spaces={\n",
    "            'learning_rate' : (0.03, 0.3, 'uniform'),\n",
    "            'l2_leaf_reg'   : (1, 7),\n",
    "            'depth'         : (4, 10),\n",
    "            'iterations'    : (10,1000)\n",
    "        },\n",
    "        #fit_params={'show_progress': True},\n",
    "        #scoring=als_scorer,\n",
    "        n_iter=30,\n",
    "        cv=3,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "    searchcv.fit(X, y)\n",
    "    return  searchcv.best_estimator_, dict(searchcv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Загружаем исходные файлы\n",
    "# ---------------------------------------\n",
    "if ((items      := load_parquet_file(s3, INFER_FILES['item_prop'])) is None or\n",
    "    (items_ctgr := load_parquet_file(s3, INFER_FILES['item_cat' ])) is None or\n",
    "    (items_avail:= load_parquet_file(s3, INFER_FILES['available'])) is None or\n",
    "    (events     := load_parquet_file(s3, INFER_FILES['event_dst'])) is None or\n",
    "    (als_params := load_pkl_file    (s3, MODEL_FILES['als_parms'])) is None or\n",
    "    (cb_model   := load_pkl_file    (s3, MODEL_FILES['cb_model' ])) is None\n",
    "):  raise Exception()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculated inference date: 2015-09-13 00:00:00\n",
      "Calculated test_time: 2015-09-06 00:00:00\n",
      "Calculated target_time: 2015-08-23 00:00:00\n",
      "Calculated top_pop_time: 2015-06-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "retrain = True\n",
    "\n",
    "# ---------------------------------------\n",
    "# Определяем опорные даты для расчетов\n",
    "# ---------------------------------------\n",
    "MS_PER_DAY     = 24*60*60*1000\n",
    "max_event_time = events['timestamp'].max()\n",
    "infer_time     = ((max_event_time-1) // MS_PER_DAY +1) * MS_PER_DAY\n",
    "infer_date     = pd.to_datetime(infer_time, unit='ms')\n",
    "logging.info(f\"Calculated inference date: {infer_date}\")\n",
    "\n",
    "# для ограничения размера матрицы взаимодействий, в режиме расчета рекомендаций возьмем только \n",
    "# пользователей, проявивших активность за последние недели (~60 тыс уникальных пользователей в неделю)\n",
    "cut_off_time   = 0 if retrain  else infer_time - 7*CONFIG['EVENT_CUT_OFF_WEEKS']*MS_PER_DAY\n",
    "if not retrain:  logging.info(f\"Calculated cut_off time: {pd.to_datetime(cut_off_time, unit='ms')}\")\n",
    "\n",
    "# в режиме переобучения моделей необходимо определить точки для разделения выборки на train/target/test\n",
    "test_time      = infer_time if not retrain  else (\n",
    "                    infer_time - 7*CONFIG['EVENT_TEST_WEEKS']*MS_PER_DAY\n",
    ")\n",
    "if  retrain:  logging.info(f\"Calculated test_time: {pd.to_datetime(test_time, unit='ms')}\")\n",
    "target_time    = infer_time if not retrain  else (\n",
    "                    test_time - 7*CONFIG['EVENT_TARGET_WEEKS']*MS_PER_DAY\n",
    ")\n",
    "if  retrain:  logging.info(f\"Calculated target_time: {pd.to_datetime(target_time, unit='ms')}\")\n",
    "# расчитываем время отсечения событий для определения АКТУАЛЬНЫХ топ-100 товаров\n",
    "top_pop_time   = infer_time - 7*CONFIG['EVENT_POPULAR_WEEKS']*MS_PER_DAY\n",
    "logging.info(f\"Calculated top_pop_time: {pd.to_datetime(top_pop_time, unit='ms')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculated top_popular: <class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   itemid     100 non-null    int64  \n",
      " 1   rating     100 non-null    int16  \n",
      " 2   pop_score  100 non-null    float64\n",
      "dtypes: float64(1), int16(1), int64(1)\n",
      "memory usage: 1.9 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_popular = events.query(\"timestamp >= @top_pop_time\")                               \\\n",
    "                    .groupby(['itemid'])['event'].value_counts().unstack(fill_value=0) \\\n",
    "                    .sort_values(by=2,ascending=False).head(100)\n",
    "\n",
    "# считаем и масштабируем рейтинг популярности\n",
    "top_popular['rating']    = calc_item_rating(top_popular)\n",
    "top_popular['pop_score'] = MinMaxScaler().fit_transform(top_popular['rating'].to_frame())\n",
    "\n",
    "# сортируем по скорингу\n",
    "top_popular = top_popular[['rating','pop_score']].sort_values(by='rating',ascending=False).reset_index()\n",
    "logging.info(f\"Calculated top_popular: {pd_info(top_popular)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runid = reg_model(None, None, None, None, None, CONFIG, artifacts={'top_popular': top_popular.to_dict()})\n",
    "#runid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "als_users: 867213\n",
      "available items: 412906\n"
     ]
    }
   ],
   "source": [
    "# пользователи, на которых будем обучать als-модель\n",
    "als_users = events.query(\"timestamp < @target_time\")['visitorid'].unique()\n",
    "logging.info(f\"als_users: {als_users.shape[0]}\")\n",
    "\n",
    "# для рекомендаций (но не для обучения!) будем использовать только доступные товары\n",
    "if  not retrain:\n",
    "    av_items = np.array(list(get_available_items (infer_time, items_ctgr, items_avail)))\n",
    "else:\n",
    "    av_items = np.array(list(get_registered_items(target_time, items_ctgr)))\n",
    "logging.info(f\"available items: {av_items.shape[0]}\")\n",
    "\n",
    "# строим матрицу взаимодействий для обучения:  als_users x av_items\n",
    "user_item, user_item_sparse = user_item_matrix(\n",
    "    events.query(\"timestamp <  @target_time\"), als_users, av_items\n",
    ")\n",
    "# валидационная матрица взаимодействий (в режиме расчета рекомендаций - ПУСТАЯ)\n",
    "user_item_val, user_item_val_sparse = user_item_matrix(\n",
    "    events.query(\"timestamp >= @target_time\"), als_users, av_items\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335d5c94c4c344a79f33e59a1ce7f424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 79, 'iterations': 75, 'learning_rate': 0.700692149436217, 'regularization': 0.02664614222120147}] => 0.50716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355c70d887944f4184b8052a05398076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 130, 'iterations': 89, 'learning_rate': 0.024953172459998858, 'regularization': 0.7722621432745812}] => 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f5300c29c1409a93b5667085bd61b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 83, 'iterations': 93, 'learning_rate': 0.00871473275220427, 'regularization': 0.04966858407544434}] => 0.50011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ccd1d21f37446293c8e7b530df5fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 127, 'iterations': 25, 'learning_rate': 0.11887602332371709, 'regularization': 0.35168661954941205}] => 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408692b9ffaf42eda6f513523fce9edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 126, 'iterations': 49, 'learning_rate': 0.08142147512462601, 'regularization': 0.22174186133335963}] => 0.49999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0cc9fff3954c2490becb7ca5542990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 118, 'iterations': 95, 'learning_rate': 0.011896933386650058, 'regularization': 0.013568825353547214}] => 0.50294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df49bdd68b084cf2ad832dbb8f5f97c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 104, 'iterations': 80, 'learning_rate': 0.033503682146853224, 'regularization': 0.5138291456389467}] => 0.50002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56a36721e9c47019a5d688b900b5d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 95, 'iterations': 93, 'learning_rate': 0.06939925065759288, 'regularization': 0.42309957790998937}] => 0.49999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c25f19a7674f1ab9b6dc142a9a07f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 145, 'iterations': 73, 'learning_rate': 0.5066023937049742, 'regularization': 0.045267530167202336}] => 0.50764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7ce4df9ddd43aa880f231f4b250398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score [{'factors': 30, 'iterations': 84, 'learning_rate': 0.2539123555141126, 'regularization': 0.019262248760035825}] => 0.50488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60cd83c547c4d1ca7a85c60d4efdd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModelFitError",
     "evalue": "NaN encountered in factors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelFitError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     als_model,_ \u001b[39m=\u001b[39m als_train(user_item_sparse, \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mals_params)\n\u001b[1;32m      4\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     als_model,als_params \u001b[39m=\u001b[39m als_train_(user_item_sparse, user_item_val_sparse)\n\u001b[1;32m      6\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mals_params: \u001b[39m\u001b[39m{\u001b[39;00mals_params\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 157\u001b[0m, in \u001b[0;36mals_train_\u001b[0;34m(csr_train, csr_val, **hyper_params)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m  estimator\u001b[39m.\u001b[39mcalc_score()\n\u001b[1;32m    143\u001b[0m searchcv \u001b[39m=\u001b[39m BayesSearchCV(\n\u001b[1;32m    144\u001b[0m     ScikitAls(random_state\u001b[39m=\u001b[39mRANDOM_STATE),\n\u001b[1;32m    145\u001b[0m     search_spaces\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     random_state\u001b[39m=\u001b[39mRANDOM_STATE,\n\u001b[1;32m    156\u001b[0m )\n\u001b[0;32m--> 157\u001b[0m searchcv\u001b[39m.\u001b[39;49mfit(csr_train)\n\u001b[1;32m    158\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m=== BEST SCORE: \u001b[39m\u001b[39m{\u001b[39;00mbest_score\u001b[39m}\u001b[39;00m\u001b[39m ===\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m  best_model, \u001b[39mdict\u001b[39m(searchcv\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/skopt/searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit):\n\u001b[1;32m    536\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBayesSearchCV doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support a callable refit, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt define an implicit score to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moptimize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 542\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    544\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/sklearn/base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1358\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1359\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1361\u001b[0m     )\n\u001b[1;32m   1362\u001b[0m ):\n\u001b[0;32m-> 1363\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m-> 1051\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m   1053\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/skopt/searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    596\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 599\u001b[0m     optim_result, score_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[1;32m    600\u001b[0m         search_space,\n\u001b[1;32m    601\u001b[0m         optimizer,\n\u001b[1;32m    602\u001b[0m         score_name,\n\u001b[1;32m    603\u001b[0m         evaluate_candidates,\n\u001b[1;32m    604\u001b[0m         n_points\u001b[39m=\u001b[39;49mn_points_adjusted,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[1;32m    608\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/skopt/searchcv.py:453\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    451\u001b[0m params_dict \u001b[39m=\u001b[39m [point_asdict(search_space, p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params]\n\u001b[0;32m--> 453\u001b[0m all_results \u001b[39m=\u001b[39m evaluate_candidates(params_dict)\n\u001b[1;32m    455\u001b[0m \u001b[39m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39m# to get the score name\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m score_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/sklearn/model_selection/_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    990\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    991\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    994\u001b[0m         )\n\u001b[1;32m    995\u001b[0m     )\n\u001b[0;32m--> 997\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    998\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    999\u001b[0m         clone(base_estimator),\n\u001b[1;32m   1000\u001b[0m         X,\n\u001b[1;32m   1001\u001b[0m         y,\n\u001b[1;32m   1002\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m   1003\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m   1004\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m   1005\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m   1006\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m   1007\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m   1010\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params),\n\u001b[1;32m   1011\u001b[0m         \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrouted_params\u001b[39m.\u001b[39;49msplitter\u001b[39m.\u001b[39;49msplit)),\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1017\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[39m=\u001b[39m warnings\u001b[39m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[39m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config_and_warning_filters)\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1988\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[39m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/sklearn/utils/parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig), warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[39m.\u001b[39mfilters \u001b[39m=\u001b[39m warning_filters\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:857\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mif\u001b[39;00m y_train \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    858\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "Cell \u001b[0;32mIn[6], line 123\u001b[0m, in \u001b[0;36mals_train_.<locals>.ScikitAls.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m als_cache\u001b[39m.\u001b[39mkeys(): \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mals \u001b[39m=\u001b[39m BayesianPersonalizedRanking(random_state\u001b[39m=\u001b[39mRANDOM_STATE, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())\n\u001b[0;32m--> 123\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mals\u001b[39m.\u001b[39;49mfit(csr_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n",
      "File \u001b[0;32mbpr.pyx:207\u001b[0m, in \u001b[0;36mimplicit.cpu.bpr.BayesianPersonalizedRanking.fit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mle_projects/mle-pr-final/.venv_mle-pr-final/lib/python3.10/site-packages/implicit/cpu/matrix_factorization_base.py:252\u001b[0m, in \u001b[0;36mMatrixFactorizationBase._check_fit_errors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m is_nan \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_factors), axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m is_nan:\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mraise\u001b[39;00m ModelFitError(\u001b[39m\"\u001b[39m\u001b[39mNaN encountered in factors\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModelFitError\u001b[0m: NaN encountered in factors"
     ]
    }
   ],
   "source": [
    "# обучаем ALS-модель\n",
    "if  not retrain:\n",
    "    als_model,_ = als_train(user_item_sparse, None, **als_params)\n",
    "else:\n",
    "    als_model,als_params = als_train_(user_item_sparse, user_item_val_sparse)\n",
    "logging.info(f\"als_params: {als_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "user_item users: 867213\n",
      "hot_users: 15545\n"
     ]
    }
   ],
   "source": [
    "# пользователи, которым будем давать персональные рекомендации\n",
    "hot_users = events.query(\"visitorid in @user_item['visitorid'].unique()\")['visitorid'].unique()\n",
    "logging.info(f\"user_item users: {hot_users.shape[0]}\")\n",
    "if  not retrain:\n",
    "    hot_users = events.query(\n",
    "        \"visitorid in @hot_users  and  timestamp >= @cut_off_time\"\n",
    "    )['visitorid'].unique()\n",
    "else:\n",
    "    hot_users = events.query(\n",
    "        \"visitorid in @hot_users  and  visitorid in @user_item_val['visitorid'].unique()\"\n",
    "    )['visitorid'].unique()\n",
    "logging.info(f\"hot_users: {hot_users.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "personal_als calculated:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 233175 entries, 0 to 233174\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   visitorid  233175 non-null  int64  \n",
      " 1   als_rank   233175 non-null  int64  \n",
      " 2   itemid     233175 non-null  int32  \n",
      " 3   als_score  233175 non-null  float32\n",
      "dtypes: float32(1), int32(1), int64(2)\n",
      "memory usage: 5.3 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# вычисляем коллаборативные рекомендации\n",
    "RECS_PER_USER = CONFIG['ALS_RECS_PER_USER']\n",
    "als_recommendations = als_model.recommend(\n",
    "    hot_users, \n",
    "    user_item_sparse[hot_users], \n",
    "    filter_already_liked_items=True, N=RECS_PER_USER\n",
    ")\n",
    "personal_als  = pd.DataFrame({\n",
    "    'itemid'   : als_recommendations[0].ravel(),\n",
    "    'als_score': als_recommendations[1].ravel()\n",
    "}, index=pd.MultiIndex.from_product(\n",
    "    [hot_users, range(RECS_PER_USER)], names=['visitorid', 'als_rank'])\n",
    ").reset_index()\n",
    "del als_recommendations #, user_item_sparse, user_item_val_sparse, user_item, user_item_val\n",
    "logging.info(f\"personal_als calculated:\\n{pd_info(personal_als)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visitorid     15545\n",
       "als_rank         15\n",
       "itemid         8620\n",
       "als_score    224166\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_als.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "similar_items calculated:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2339130 entries, 0 to 2339129\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   itemid      2339130 non-null  int64  \n",
      " 1   sim_rank    2339130 non-null  int64  \n",
      " 2   sim_itemid  2339130 non-null  int32  \n",
      " 3   sim_score   2339130 non-null  float32\n",
      "dtypes: float32(1), int32(1), int64(2)\n",
      "memory usage: 53.5 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# получаем подобные для всех товаров, известных модели\n",
    "SIMS_PER_ITEM = CONFIG['ALS_SIMS_PER_ITEM']\n",
    "sim_items = als_model.similar_items(user_item['itemid'].unique(), N=SIMS_PER_ITEM)\n",
    "\n",
    "similar_items = pd.DataFrame({\n",
    "    'sim_itemid': sim_items[0].ravel(),\n",
    "    'sim_score' : sim_items[1].ravel()\n",
    "}, index=pd.MultiIndex.from_product(\n",
    "    [user_item['itemid'].unique(), range(SIMS_PER_ITEM)], names=['itemid', 'sim_rank']\n",
    ")).reset_index()\n",
    "del sim_items, user_item, user_item_val, als_model\n",
    "logging.info(f\"similar_items calculated:\\n{pd_info(similar_items)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemid         155942\n",
       "sim_rank           15\n",
       "sim_itemid     155820\n",
       "sim_score     1513166\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_items.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем информацию из personal_als, similar_items и top_popular в привязке к visitorid\n",
    "candidades = personal_als[['visitorid','itemid']].merge(\n",
    "    similar_items, how='left', on='itemid'\n",
    ").groupby(['visitorid','sim_itemid']).agg(\n",
    "    sim_score=('sim_score','max')\n",
    ").reset_index().rename(\n",
    "    columns={'sim_itemid': 'itemid'} \n",
    ").merge(\n",
    "    personal_als[['visitorid','itemid','als_score']], how='outer', on=['visitorid','itemid']\n",
    ").merge(\n",
    "    top_popular[['itemid','pop_score']], how='left', on='itemid'\n",
    ")\n",
    "del personal_als\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "candidades:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2290304 entries, 0 to 2290303\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   visitorid  2290304 non-null  int64  \n",
      " 1   itemid     2290304 non-null  int64  \n",
      " 2   sim_score  2289218 non-null  float32\n",
      " 3   als_score  233175 non-null   float32\n",
      " 4   pop_score  19219 non-null    float64\n",
      " 5   target     2290304 non-null  int8   \n",
      "dtypes: float32(2), float64(1), int64(2), int8(1)\n",
      "memory usage: 72.1 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# формируем таргет для модели ранжирования (добавления в корзину и покупки)\n",
    "if  retrain:\n",
    "    events_target = events.query(\"timestamp >= @target_time and timestamp < @test_time\").copy()\n",
    "    events_target['target'] = (events_target['event'] > 0).astype(np.int8)\n",
    "\n",
    "    # расширяем состав candidades за счет положительных сэмплов из events_target\n",
    "    candidades = candidades.merge(\n",
    "        events_target.groupby(['visitorid','itemid']).agg(target=('target','max')).reset_index().query(\n",
    "            \"visitorid in @hot_users and target > 0\"\n",
    "        ), \n",
    "        how='outer', on=['visitorid','itemid']\n",
    "    )\n",
    "    candidades[\"target\"] = candidades[\"target\"].fillna(0).astype(np.int8)\n",
    "logging.info(f\"candidades:\\n{pd_info(candidades)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    2289095\n",
       "1       1209\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidades['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем свойства товаров, актуальные на target_time\n",
    "item_props = get_item_properties(target_time-1, items)\n",
    "\n",
    "# отбираем категориальные свойства (с количеством значений до 10-и)\n",
    "prop_vals = item_props.groupby('property').agg(nvalues=('value_code','max')).reset_index()\n",
    "categorical_props = prop_vals.query(\"nvalues <= 5\")['property'].unique()\n",
    "categorical_props.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "user_item_prop_score:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2290304 entries, 0 to 2290303\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   visitorid   2290304 non-null  int64  \n",
      " 1   itemid      2290304 non-null  int64  \n",
      " 2   prop_score  2290304 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 52.4 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# выясняем предпочтения пользователей по категориальным свойствам товаров\n",
    "user_item_prop = candidades[['visitorid','itemid']].merge(\n",
    "    item_props.query(\"itemid in @candidades['itemid'].unique() and property in @categorical_props\"),\n",
    "    how='left', on='itemid'\n",
    ")\n",
    "user_prop_score = user_item_prop.groupby(['visitorid','property']).agg(\n",
    "    prop_score=('itemid','nunique')\n",
    ").reset_index()\n",
    "user_item_prop_score = user_item_prop.merge(\n",
    "    user_prop_score, how='left', on=['visitorid','property']\n",
    ").groupby(['visitorid','itemid']).agg(\n",
    "    prop_score=('prop_score','mean')\n",
    ").fillna(0).reset_index()\n",
    "del user_item_prop, user_prop_score\n",
    "logging.info(f\"user_item_prop_score:\\n{pd_info(user_item_prop_score)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код для условного выполнения ячеек, начинающихся с %%exec_if <condition>\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "@register_cell_magic\n",
    "def exec_if(line, cell):\n",
    "    try:\n",
    "        if eval(line): get_ipython().run_cell(cell)\n",
    "    except:\n",
    "        pass\n",
    "    return\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%exec_if False  # НЕ СЧИТАЕМ в связи с малозначимостью данных признаков, исходя из cb_model.get_feature_importance\n",
    "\n",
    "# ... а также, предпочтения пользователей по категориям товаров\n",
    "\n",
    "user_item_cat = events_train.query(\n",
    "    \"event>0 and visitorid in @hot_users\"             # берем только целевые события\n",
    ")[['visitorid','itemid','categoryid','root']]\n",
    "\n",
    "user_cat_score = user_item_cat.groupby(['visitorid','categoryid']).agg(\n",
    "    cat_score=('itemid','nunique')\n",
    ").reset_index()\n",
    "\n",
    "user_root_score = user_item_cat.groupby(['visitorid','root']).agg(\n",
    "    root_score=('itemid','nunique')\n",
    ").reset_index()\n",
    "\n",
    "user_item_cat_score = user_item_cat.merge(\n",
    "    user_cat_score, how='left', on=['visitorid','categoryid']\n",
    ").groupby(['visitorid','itemid']).agg(\n",
    "    cat_score=('cat_score','mean')\n",
    ").reset_index().merge(\n",
    "    candidades[['visitorid','itemid']], how='right', on=['visitorid','itemid']\n",
    ").fillna(0)\n",
    "\n",
    "user_item_root_score = user_item_cat.merge(\n",
    "    user_root_score, how='left', on=['visitorid','root']\n",
    ").groupby(['visitorid','itemid']).agg(\n",
    "    root_score=('root_score','mean')\n",
    ").reset_index().merge(\n",
    "    candidades[['visitorid','itemid']], how='right', on=['visitorid','itemid']\n",
    ").fillna(0)\n",
    "\n",
    "del user_item_cat, user_cat_score, user_root_score\n",
    "user_item_cat_score.info(show_counts=True)\n",
    "user_item_root_score.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализуем user_item_prop_score по каждому пользователю\n",
    "def normalize_col_by_col(df: pd.DataFrame, col: str, by_col: str):\n",
    "    from sklearn.preprocessing import normalize\n",
    "    tmp      = df.sort_values(by=by_col)\n",
    "    tmp[col] = tmp.groupby(by_col)[col].apply(\n",
    "        lambda x: normalize(x.values.reshape(-1,1), norm='l1', axis=0, copy=True, return_norm=True)[0].ravel()\n",
    "    ).explode(col).values.astype('float32')\n",
    "    df[col]  = tmp[col]\n",
    "normalize_col_by_col(user_item_prop_score, 'prop_score', 'visitorid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "user_item_hit_score:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2290304 entries, 0 to 2290303\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   visitorid  2290304 non-null  int64  \n",
      " 1   itemid     2290304 non-null  int64  \n",
      " 2   hit_score  2290304 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 52.4 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# считаем hit_score\n",
    "user_item_hit_score = events.query(\"visitorid in @hot_users and timestamp < @target_time\").groupby(\n",
    "    ['visitorid','itemid']\n",
    ").agg(\n",
    "    hit_score=('event','nunique')\n",
    ").reset_index().merge(\n",
    "    candidades[['visitorid','itemid']], how='right', on=['visitorid','itemid']\n",
    ").fillna(0)\n",
    "logging.info(f\"user_item_hit_score:\\n{pd_info(user_item_hit_score)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "user_features:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15545 entries, 0 to 15544\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   visitorid      15545 non-null  int64  \n",
      " 1   stage          15545 non-null  int64  \n",
      " 2   nclicks        15545 non-null  int64  \n",
      " 3   nbuys          15545 non-null  int64  \n",
      " 4   click_per_day  15545 non-null  float64\n",
      " 5   buy_per_click  15545 non-null  float64\n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 728.8 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# добавляем признаки пользователя - \"стаж\" и активность\n",
    "user_features = events.query(\"visitorid in @hot_users and timestamp < @target_time\").groupby(\"visitorid\").agg(\n",
    "    stage  =('timestamp', lambda x: (infer_date - pd.to_datetime(x.min(),unit='ms')).days +1),\n",
    "    nclicks=('timestamp', 'count'),\n",
    "    nbuys  =('transactionid', 'count')\n",
    ").reset_index()\n",
    "user_features[\"click_per_day\"] = user_features[\"nclicks\"] / user_features[\"stage\"]\n",
    "user_features[\"buy_per_click\"] = user_features[\"nbuys\"]   / user_features[\"nclicks\"]\n",
    "logging.info(f\"user_features:\\n{pd_info(user_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final candidades:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2290304 entries, 0 to 2290303\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   visitorid      2290304 non-null  int64  \n",
      " 1   itemid         2290304 non-null  int64  \n",
      " 2   sim_score      2290304 non-null  float32\n",
      " 3   als_score      233175 non-null   float32\n",
      " 4   pop_score      19219 non-null    float64\n",
      " 5   target         2290304 non-null  int8   \n",
      " 6   prop_score     2290304 non-null  float32\n",
      " 7   hit_score      2290304 non-null  float64\n",
      " 8   stage          2290304 non-null  int64  \n",
      " 9   click_per_day  2290304 non-null  float64\n",
      " 10  buy_per_click  2290304 non-null  float64\n",
      "dtypes: float32(3), float64(4), int64(3), int8(1)\n",
      "memory usage: 150.7 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# вносим сформированные дополнительные признаки в candidades\n",
    "candidades = candidades.merge(\n",
    "    user_item_prop_score, how='left', on=['visitorid','itemid']\n",
    ").merge(\n",
    "    user_item_hit_score,  how='left', on=['visitorid','itemid']\n",
    ").merge(\n",
    "    user_features[['visitorid','stage','click_per_day','buy_per_click']], how='left', on=['visitorid']\n",
    ")\n",
    "# объединяем als-скоринги\n",
    "candidades['sim_score'] = candidades['als_score'].fillna(1) * candidades['sim_score'].fillna(0)\n",
    "logging.info(f\"final candidades:\\n{pd_info(candidades)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем список признаков\n",
    "feature_cols   = ['sim_score','pop_score','prop_score','hit_score',\n",
    "                    'stage','click_per_day','buy_per_click']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "candidades for catboost train:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 65767 entries, 5395 to 2286361\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   visitorid      65767 non-null  int64  \n",
      " 1   itemid         65767 non-null  int64  \n",
      " 2   sim_score      65767 non-null  float32\n",
      " 3   als_score      6585 non-null   float32\n",
      " 4   pop_score      679 non-null    float64\n",
      " 5   target         65767 non-null  int8   \n",
      " 6   prop_score     65767 non-null  float32\n",
      " 7   hit_score      65767 non-null  float64\n",
      " 8   stage          65767 non-null  int64  \n",
      " 9   click_per_day  65767 non-null  float64\n",
      " 10  buy_per_click  65767 non-null  float64\n",
      " 11  cb_score       65767 non-null  float64\n",
      " 12  rank           65767 non-null  int64  \n",
      "dtypes: float32(3), float64(5), int64(4), int8(1)\n",
      "memory usage: 5.8 MB\n",
      "\n",
      "catboost parameters:\n",
      "OrderedDict([('depth', 9), ('iterations', 640), ('l2_leaf_reg', 1), ('learning_rate', 0.036416051470430436)])\n",
      "feature_importance:\n",
      "                      fi\n",
      "sim_score      47.884583\n",
      "stage          14.246105\n",
      "prop_score     13.616518\n",
      "click_per_day  12.770627\n",
      "buy_per_click   5.949638\n",
      "hit_score       4.815878\n",
      "pop_score       0.716651\n"
     ]
    }
   ],
   "source": [
    "if  retrain:    # --------------------------------------- #\n",
    "                # -   Переобучаем модель ранжирования   - #\n",
    "                # --------------------------------------- #\n",
    "    # в кандидатах оставляем только тех пользователей, у которых есть хотя бы один положительный таргет\n",
    "    candidades_for_train = candidades.groupby(\"visitorid\").filter(lambda x: x[\"target\"].sum() > 0)\n",
    "\n",
    "    # убираем неинформативные дубликаты (гарантированно оставляя положительный таргет)\n",
    "    candidades_for_train = candidades_for_train.sort_values(by='target',ascending=False).drop_duplicates(\n",
    "        subset=['visitorid','itemid']+feature_cols, keep='first'\n",
    "    )\n",
    "    logging.info(f\"candidades for catboost train:\\n{pd_info(candidades_for_train)}\")\n",
    "\n",
    "    # Обучаем ранжирующую модель с подбором гиперпараметров\n",
    "    train_data = Pool(data=candidades_for_train[feature_cols], label=candidades_for_train['target'])\n",
    "    #cb_model, cb_params = cb_train (train_data)\n",
    "    cb_model, cb_params = cb_train_new (candidades_for_train[feature_cols], candidades_for_train['target'])\n",
    "    logging.info(f\"catboost parameters:\\n{cb_params}\")\n",
    "\n",
    "    # получаем оценку важности признаков\n",
    "    feature_importance = pd.DataFrame(cb_model.get_feature_importance(), index=feature_cols, columns=[\"fi\"])\n",
    "    feature_importance = feature_importance.sort_values(by=\"fi\", ascending=False)\n",
    "    logging.info(f\"feature_importance:\\n{feature_importance}\")\n",
    "\n",
    "    # сохраняем данные\n",
    "    #save_to_pkl(als_params, s3, MODEL_FILES['als_parms'])\n",
    "    #save_to_pkl(cb_params,  s3, MODEL_FILES['cb_parms'])\n",
    "    #save_to_pkl(cb_model,   s3, MODEL_FILES['cb_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'Recall': 1.0, 'Logloss': 0.0071001575991267545}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nan_mode': 'Min',\n",
       " 'eval_metric': 'Recall',\n",
       " 'iterations': 640,\n",
       " 'sampling_frequency': 'PerTree',\n",
       " 'leaf_estimation_method': 'Newton',\n",
       " 'random_score_type': 'NormalWithModelSizeDecrease',\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'penalties_coefficient': 1,\n",
       " 'boosting_type': 'Plain',\n",
       " 'model_shrink_mode': 'Constant',\n",
       " 'feature_border_type': 'GreedyLogSum',\n",
       " 'bayesian_matrix_reg': 0.10000000149011612,\n",
       " 'eval_fraction': 0,\n",
       " 'force_unit_auto_pair_weights': False,\n",
       " 'l2_leaf_reg': 1,\n",
       " 'random_strength': 1,\n",
       " 'rsm': 1,\n",
       " 'boost_from_average': False,\n",
       " 'model_size_reg': 0.5,\n",
       " 'pool_metainfo_options': {'tags': {}},\n",
       " 'subsample': 0.800000011920929,\n",
       " 'use_best_model': False,\n",
       " 'class_names': [0, 1],\n",
       " 'random_seed': 42,\n",
       " 'depth': 9,\n",
       " 'posterior_sampling': False,\n",
       " 'border_count': 254,\n",
       " 'class_weights': [1, 53.397850036621094],\n",
       " 'classes_count': 0,\n",
       " 'auto_class_weights': 'Balanced',\n",
       " 'sparse_features_conflict_fraction': 0,\n",
       " 'leaf_estimation_backtracking': 'AnyImprovement',\n",
       " 'best_model_min_trees': 1,\n",
       " 'model_shrink_rate': 0,\n",
       " 'min_data_in_leaf': 1,\n",
       " 'loss_function': 'Logloss',\n",
       " 'learning_rate': 0.03641605004668236,\n",
       " 'score_function': 'Cosine',\n",
       " 'task_type': 'CPU',\n",
       " 'leaf_estimation_iterations': 10,\n",
       " 'bootstrap_type': 'MVS',\n",
       " 'max_leaves': 512}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.get_all_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions    = cb_model.predict_proba(train_data)\n",
    "candidades_for_train[\"cb_score\"] = predictions[:,1]\n",
    "candidades_for_train.sort_values(['visitorid', 'cb_score', 'sim_score', 'hit_score', 'prop_score', 'pop_score'], \n",
    "                    ascending=[True, False, False, False, False, False], inplace=True\n",
    ")\n",
    "candidades_for_train[\"rank\"] = candidades_for_train.groupby(\"visitorid\")[\"cb_score\"].cumcount() +1\n",
    "#candidades_for_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 527 entries, 2286361 to 2286361\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   label          527 non-null    int8   \n",
      " 1   visitorid      527 non-null    int64  \n",
      " 2   itemid         527 non-null    int64  \n",
      " 3   sim_score      15 non-null     float32\n",
      " 4   als_score      5 non-null      float32\n",
      " 5   pop_score      2 non-null      float64\n",
      " 6   target         15 non-null     float64\n",
      " 7   prop_score     15 non-null     float32\n",
      " 8   hit_score      15 non-null     float64\n",
      " 9   stage          15 non-null     float64\n",
      " 10  click_per_day  15 non-null     float64\n",
      " 11  buy_per_click  15 non-null     float64\n",
      " 12  cb_score       15 non-null     float64\n",
      " 13  rank           15 non-null     float64\n",
      "dtypes: float32(3), float64(8), int64(2), int8(1)\n",
      "memory usage: 52.0 KB\n"
     ]
    }
   ],
   "source": [
    "candidades_for_eval = events.query(\"timestamp >= @test_time and visitorid in @hot_users and event > 0\")  \\\n",
    "                            .groupby(['visitorid','itemid']).agg(label=('event','max'))    \\\n",
    "                            .merge(candidades_for_train, #.query(\"cb_score > 0.5\"), \n",
    "                                   how='left', left_index=True, right_on=['visitorid','itemid'])\n",
    "candidades_for_eval.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.028462998102466792]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidades_for_eval['tgt'] = candidades_for_eval['cb_score'].notna().astype(int)\n",
    "candidades_for_eval['lbl'] = (candidades_for_eval['label'] > 0).astype(int)\n",
    "eval_metric(candidades_for_eval['lbl'].tolist(), candidades_for_eval['tgt'].tolist(), metric='Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 16)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidades_for_eval.query(\"lbl > 0 and tgt>0\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем скоринг рекомендаций\n",
    "inference_data = Pool(data=candidades[feature_cols])\n",
    "predictions    = cb_model.predict_proba(inference_data)\n",
    "\n",
    "# сортируем в соответствии с feature importance и проставим rank, начиная с 1\n",
    "candidades[\"cb_score\"] = predictions[:,1]\n",
    "candidades.sort_values(['visitorid', 'cb_score', 'sim_score', 'hit_score', 'prop_score', 'pop_score'], \n",
    "                    ascending=[True, False, False, False, False, False], inplace=True\n",
    ")\n",
    "candidades[\"rank\"] = candidades.groupby(\"visitorid\")[\"cb_score\"].cumcount() +1\n",
    "\n",
    "# формируем финальные рекомендации с минимально необходимым для prod набором полей\n",
    "max_recommendations_per_user = 100\n",
    "final_recommendations = candidades.query(\n",
    "    \"rank <= @max_recommendations_per_user\"\n",
    ")[['visitorid','itemid','rank']] #,'cb_score','als_score']+feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain:\n",
    "    candidades_for_eval = events.query(\"timestamp >= @test_time and visitorid in @hot_users and event > 0\")  \\\n",
    "                                .groupby(['visitorid','itemid']).agg(label=('event','max'))    \\\n",
    "                                .merge(candidades, #.query(\"cb_score > 0.5\"), \n",
    "                                 how='left', left_index=True, right_on=['visitorid','itemid'])\n",
    "    candidades_for_eval['tgt'] = candidades_for_eval['cb_score'].notna().astype(int)\n",
    "    candidades_for_eval['lbl'] = (candidades_for_eval['label'] > 0).astype(int)\n",
    "    metrics = eval_metric(candidades_for_eval['lbl'].tolist(), candidades_for_eval['tgt'].tolist(), metric='Recall')\n",
    "    #reg_model(cb_model, candidades_for_train[feature_cols], candidades_for_train['target'], {'Recall':metrics[0]}, \n",
    "    #          cb_params, CONFIG, artifacts={'feature_importance.pkl': feature_importance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07210626185958255]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 10,\n",
       " 'iterations': 998,\n",
       " 'l2_leaf_reg': 2,\n",
       " 'learning_rate': 0.12927086924414405}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(cb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_recommendations calculated:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9414371 entries, 42 to 11842159\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count    Dtype\n",
      "---  ------     --------------    -----\n",
      " 0   visitorid  9414371 non-null  int64\n",
      " 1   itemid     9414371 non-null  int32\n",
      " 2   rank       9414371 non-null  int64\n",
      "dtypes: int32(1), int64(2)\n",
      "memory usage: 251.4 MB\n",
      "\n",
      "save_to_parquet:\n",
      "s3-student-mle-20250228-1d75c84a52/Diplom/recommendations/top_popular.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   itemid     100 non-null    int64  \n",
      " 1   rating     100 non-null    int16  \n",
      " 2   pop_score  100 non-null    float64\n",
      "dtypes: float64(1), int16(1), int64(1)\n",
      "memory usage: 1.9 KB\n",
      "\n",
      "save_to_parquet:\n",
      "s3-student-mle-20250228-1d75c84a52/Diplom/recommendations/similar_items.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 578625 entries, 0 to 578624\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   itemid      578625 non-null  int64  \n",
      " 1   sim_rank    578625 non-null  int64  \n",
      " 2   sim_itemid  578625 non-null  int32  \n",
      " 3   sim_score   578625 non-null  float32\n",
      "dtypes: float32(1), int32(1), int64(2)\n",
      "memory usage: 13.2 MB\n",
      "\n",
      "save_to_parquet:\n",
      "s3-student-mle-20250228-1d75c84a52/Diplom/recommendations/final_recommendations.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9414371 entries, 42 to 11842159\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count    Dtype\n",
      "---  ------     --------------    -----\n",
      " 0   visitorid  9414371 non-null  int64\n",
      " 1   itemid     9414371 non-null  int32\n",
      " 2   rank       9414371 non-null  int64\n",
      "dtypes: int32(1), int64(2)\n",
      "memory usage: 251.4 MB\n",
      "\n",
      "save_to_parquet:\n",
      "s3-student-mle-20250228-1d75c84a52/Diplom/recommendations/ranked_candidades.parquet\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11842188 entries, 42 to 11842181\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count     Dtype  \n",
      "---  ------         --------------     -----  \n",
      " 0   visitorid      11842188 non-null  int64  \n",
      " 1   itemid         11842188 non-null  int32  \n",
      " 2   sim_score      11842188 non-null  float32\n",
      " 3   als_score      1712145 non-null   float32\n",
      " 4   pop_score      160633 non-null    float64\n",
      " 5   prop_score     11842188 non-null  float32\n",
      " 6   hit_score      11842188 non-null  float64\n",
      " 7   stage          11842188 non-null  int64  \n",
      " 8   click_per_day  11842188 non-null  float64\n",
      " 9   buy_per_click  11842188 non-null  float64\n",
      " 10  cb_score       11842188 non-null  float64\n",
      " 11  rank           11842188 non-null  int64  \n",
      "dtypes: float32(3), float64(5), int32(1), int64(3)\n",
      "memory usage: 993.8 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not retrain:           # --------------------------------------- #\n",
    "                # -    Завершаем расчет рекомендаций    - #\n",
    "                # --------------------------------------- #\n",
    "    # получаем скоринг рекомендаций\n",
    "    inference_data = Pool(data=candidades[feature_cols])\n",
    "    predictions    = cb_model.predict_proba(inference_data)\n",
    "\n",
    "    # сортируем в соответствии с feature importance и проставим rank, начиная с 1\n",
    "    candidades[\"cb_score\"] = predictions[:,1]\n",
    "    candidades.sort_values(['visitorid', 'cb_score', 'sim_score', 'hit_score', 'prop_score', 'pop_score'], \n",
    "                        ascending=[True, False, False, False, False, False], inplace=True\n",
    "    )\n",
    "    candidades[\"rank\"] = candidades.groupby(\"visitorid\")[\"cb_score\"].cumcount() +1\n",
    "\n",
    "    # формируем финальные рекомендации с минимально необходимым для prod набором полей\n",
    "    max_recommendations_per_user = 100\n",
    "    final_recommendations = candidades.query(\n",
    "        \"rank <= @max_recommendations_per_user\"\n",
    "    )[['visitorid','itemid','rank']] #,'cb_score','als_score']+feature_cols]\n",
    "    logging.info(f\"final_recommendations calculated:\\n{pd_info(final_recommendations)}\")\n",
    "\n",
    "    # сохраняем рекомендации\n",
    "    save_to_parquet(top_popular,           s3, PROD_FILES['top_pop'])\n",
    "    save_to_parquet(similar_items,         s3, PROD_FILES['similar'])\n",
    "    save_to_parquet(final_recommendations, s3, PROD_FILES['final'  ])\n",
    "\n",
    "    # на всякий случай сохраняем candidades с полным набором полей\n",
    "    save_to_parquet(candidades,            s3, PROD_FILES['ranked'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mle-pr-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
